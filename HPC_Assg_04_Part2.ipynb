{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685413377810,"user":{"displayName":"Dnyaneshwari Takalkar","userId":"04966518559784285192"},"user_tz":-330},"id":"hMdswNUVKt3k","outputId":"f2e44028-911c-48b2-d977-b340591d6d66"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!/usr/local/cuda/bin/nvcc --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685413381949,"user":{"displayName":"Dnyaneshwari Takalkar","userId":"04966518559784285192"},"user_tz":-330},"id":"-BPtbSweK_4o","outputId":"1709307a-e789-45cb-a8ab-d0e75edcf75a"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6307,"status":"ok","timestamp":1685413397139,"user":{"displayName":"Dnyaneshwari Takalkar","userId":"04966518559784285192"},"user_tz":-330},"id":"19jgw95xLAko","outputId":"70075478-a245-4a3a-e394-eb68a101c7a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-n_9yugc1\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-n_9yugc1\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=4825a60dac8fe70e01bb01115640615ecc7de6863a1b9b228e0b8086b75f7eb4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0hi9ojwi/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n"]}],"source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685413405275,"user":{"displayName":"Dnyaneshwari Takalkar","userId":"04966518559784285192"},"user_tz":-330},"id":"ydmu4CMNLAnv","outputId":"43a54d9c-4e7d-470a-9404-c73b0aa3013b"},"outputs":[{"output_type":"stream","name":"stdout","text":["created output directory at /content/src\n","Out bin /content/result.out\n"]}],"source":["# Commented out IPython magic to ensure Python compatibility.\n","%load_ext nvcc_plugin"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1460,"status":"ok","timestamp":1685286472693,"user":{"displayName":"pradnya gaykar","userId":"01494972373452165658"},"user_tz":-330},"id":"KmfQSNT6LArh","outputId":"6592296b-8f9f-47e4-b021-b413040cec66"},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (4116449510.py, line 10)","output_type":"error","traceback":["\u001b[1;36m  Cell \u001b[1;32mIn[17], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    __global__ void mul_r(int *a, int *b, int *c){\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["# Commented out IPython magic to ensure Python compatibility. \n","%%cu \n","\n"," #include <cuda.h>\n"," #include <stdio.h>\n"," #include <stdlib.h>\n"," #include <time.h>\n"," #define m 10\n"," __global__ void mul_r(int *a, int *b, int *c){\n"," \n"," \t\t\tint tid = threadIdx.x;\n"," \t\t\tif (tid < m){\n"," \t\t\t\t\t\tc[tid]= a[tid] * b[tid];\n"," \t\t\t\t\t\t}\n"," \n"," \t\t}\n"," \n"," \t\n"," \t\n"," int main(){\n"," \t\t\tint  n, c, d, fst[10][10], snd[10][10], t_snd[10][10];\n"," \t\t\tint row,col,sum_c, a[10], b[10], ans[10];\n"," \t\t\t\n","  /*\n","    printf(\"Enter the number of rows and columns of matrix\\n\");\n","    scanf(\"%d%d\", &m, &n);\n","    */\n"," n=m;  //square matrix only\n","    //printf(\"Enter the elements of first matrix\\n\");\n","    //for true randum value of vector\n"," //srand(time(0));\n","    for (c = 0; c < m; c++)\n","    {\n","    \n","       for (d = 0; d < n; d++)\n"," \t  {\n","          //scanf(\"%d\", &first[c][d]);\n"," \t\t \n"," \t\t fst[c][d]=rand()%10+1;\n"," \t\t}\n"," \t}\n"," \tprintf(\"display the elements of first matrix\\n\");\t \n"," \tfor (c = 0; c < m; c++) {\n","       for (d = 0 ; d < n; d++) {\n","         \n"," \t\t\t\t\t\t\tprintf(\"%d\\t\", fst[c][d]);\n"," \t\t\t\t\t\t\t\t}\n"," \t\t\t\t\t\t\t\t printf(\"\\n\");\t \n"," \t\t\t\t\t\t\t}\n","      \n"," \t// take next matrix\n"," \t//for true randum value of vector\n","  //srand(time(0));\n","    for (c = 0; c < m; c++)\n","    {\n","    \n","       for (d = 0; d < n; d++)\n"," \t  {\n","          //scanf(\"%d\", &first[c][d]);\n"," \t\t \n"," \t\t snd[c][d]=rand()%10+1;\n"," \t\t}\n"," \t}\n"," \tprintf(\"display the elements of second matrix\\n\");\t \n"," \tfor (c = 0; c < m; c++) {\n","       for (d = 0 ; d < n; d++) {\n","         \n"," \t\t\t\t\t\t\tprintf(\"%d\\t\", snd[c][d]);\n"," \t\t\t\t\t\t\t\t}\n"," \t\t\t\t\t\t\t\t printf(\"\\n\");\t \n"," \t\t\t\t\t\t\t}\n"," \t// transpose of  second matrix\n"," \tfor(c=0; c<m; c++)\n","         for(d=0; d<n; d++)\n","         {\n","             t_snd[d][c] = snd[c][d];\n","         }\n"," \n","     // Displaying the transpose of matrix a\n","     printf(\"\\nTranspose of second Matrix:\\n\");\n","     for (c = 0; c < n; c++) {\n","       for (d = 0 ; d < m; d++) {\n","         \n"," \t\t\t\t\t\tprintf(\"%d\\t\", t_snd[c][d]);\n"," \t\t\t\t\t\n"," \t\t\t\t\t\t\t\t}\n"," \t\t\t\t\t\t\t\t printf(\"\\n\");\t \n"," \t\t\t\t\t\t\t}\n"," \t\t\t\t\t\n","     // now multiply on cuda\n"," \tint *dev_a, *dev_b,*dev_ans;\n"," \tcudaError_t err=cudaSuccess;\n"," \t// allocate memory on GPU\n"," \terr=cudaMalloc((void**)&dev_a,m * sizeof(int)); \n"," \tif (err !=cudaSuccess)\n"," \t{ \tprintf(\"failed to  allocate on device \\n\");\n"," \tprintf(\"error is:\\n\",cudaGetErrorString(err));\n"," \texit(EXIT_FAILURE);\n"," \t}\n"," \t//printf(\"first  ok\\n\");\n"," \tcudaMalloc((void**)&dev_b,m * sizeof(int)); \n"," \tcudaMalloc((void**)&dev_ans,m * sizeof(int)); \n"," \t//printf(\"first finished ok\\n\");\n"," \trow=0;\n"," \tcol=0;\n","   cudaEvent_t start, end;\n","   cudaEventCreate(&start);\n","   cudaEventCreate(&end);\n","   cudaEventRecord(start);\t  \n"," \n"," \tfor(row=0; row<m; row++){\n"," \t\t\n"," \t for (d = 0 ; d < m; d++) {\n","         \n"," \t\t\t\t\t\ta[d]=fst[row][d];\n"," \t\t\t\t\t\n"," \t\t\t\t\t\t\t\t}\n"," \t\t\t\t\t\t\t// printf(\"ok a\\n\");\n"," \t\tcudaMemcpy(dev_a,a,m*sizeof(int), cudaMemcpyHostToDevice);\t\n"," \tfor (col=0; col<m; col++){\t\n"," \t for (d= 0 ; d < m; d++) {\n","         \n"," \t\t\t\t\t\tb[d]=t_snd[col][d];\n"," \t\t\t\t\t\tans[d]=0;\n"," \t\t\t\t\t\n"," \t\t\t\t\t\t\t\t}\n"," \t\t\t\t\t\t\t// printf(\"ok b\\n\");\n"," \t\tcudaMemcpy(dev_b,b,m*sizeof(int), cudaMemcpyHostToDevice);\t\n"," \t\tcudaMemcpy(dev_ans,ans,m*sizeof(int), cudaMemcpyHostToDevice);\n"," \t//\tprintf(\"calling GPU\\n\");\n"," \t\tmul_r<<<1,m>>>(dev_a,dev_b,dev_ans);\n"," \t\terr=cudaMemcpy(ans,dev_ans,m*sizeof(int), cudaMemcpyDeviceToHost);\n"," \t\tif (err !=cudaSuccess)\n"," \t\t\t{ \tprintf(\"failed to  copy from device \\n\");\n"," \t\t\t\texit(EXIT_FAILURE);\n"," \t\t\t}\n"," \t//printf(\"GPU returned\\n\");\t\t\t\t\t\t\n"," \t//a=fst[0];\n"," \tsum_c=0;\n"," \t for (d = 0 ; d < m; d++) {\n","         \n"," \t\t\t\t\t\t//printf(\"%d\\t\", ans[d]);\n"," \t\t\t\t\tsum_c+=ans[d];\n"," \t\t\t\t\t\t\t\t}\n"," \tsnd[row][col]=sum_c;\n"," \t\n"," \t\n"," \t\n"," \t//printf(\"one element=%d\\n\",snd[row][col]);\n"," \t\t\t\t\t\t\t\t// printf(\"\\n\");\t \n"," \t\t\t\t\t\t\t\n"," \t}\n"," \t}\n"," \t//\n"," \tcudaEventRecord(end);\n","   cudaEventSynchronize(end);\n","   float time = 0;\n","   cudaEventElapsedTime(&time, start, end);\n","   printf(\"execution time=%f\\n\",time);\n"," //\n"," \tprintf(\" Matrix multipliation ans=:\\n\");\n","     for (c = 0; c < n; c++) {\n","       for (d = 0 ; d < m; d++) {\n","         \n"," \t\t\t\t\t\tprintf(\"%d\\t\", snd[c][d]);\n"," \t\t\t\t\t\n"," \t\t\t\t\t\t\t\t}\n"," \t\t\t\t\t\t\t\t printf(\"\\n\");\t \n"," \t\t\t\t\t\t\t}\n"," \t//\n"," \t\t\treturn 0;\n"," \t\t\t\t}\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qRI4yVlLAtm"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}